{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics & Linear Regression\n",
    "\n",
    "### In this session you will have an opportunity to interact with the MLlib for Statistics & Linear Regression\n",
    "1. Read a CSV file to a DataFrame\n",
    "2. Convert to rdd\n",
    "2. Do some basic Stats - mean, sd\n",
    "3. Exercise on Correlation\n",
    "4. Linear Regression mpg ~ .\n",
    "4. Lasso & Ridge Regression\n",
    "\n",
    "The Coding Exercises would give a good start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "print \"Running Spark Version %s\" % (sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "conf = SparkConf()\n",
    "print conf.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pytz import timezone\n",
    "print \"Last run @%s\" % (datetime.datetime.now(timezone('US/Pacific')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cars = sqlContext.read.load('cars_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cars.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_cars.show(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cars = df_cars.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars_rdd = df_cars.map(lambda x:[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "summary = Statistics.colStats(cars_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print str(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in summary.min():\n",
    "    print \"|%6.2f\" % x,\n",
    "print\n",
    "for x in summary.mean():\n",
    "    print \"|%6.2f\" % x,\n",
    "print\n",
    "for x in summary.max():\n",
    "    print \"|%6.2f\" % x,\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate & Plot Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hp = cars_rdd.map(lambda x: x[0][2])\n",
    "weight = cars_rdd.map(lambda x: x[0][10])\n",
    "print '%2.3f' % Statistics.corr(hp, weight, method=\"pearson\")\n",
    "print '%2.3f' % Statistics.corr(hp, weight, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ggplot import *\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame({'HP': hp.collect(),'Weight':weight.collect()})\n",
    "\n",
    "ggplot(df, aes(x='HP', y='Weight')) +\\\n",
    "  geom_point() + labs(title=\"Car-Attributes\", x=\"Horsepower\", y=\"Weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Excrcise\n",
    "1. Calculate the correlation between Rear Axle Ratio & the Width\n",
    "2. Plot & verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ra_ratio = cars_rdd.<FILL IN>\n",
    "width = cars_rdd.<FILL IN>\n",
    "print '%2.3f' % Statistics.corr(ra_ratio, width, method=\"pearson\")\n",
    "print '%2.3f' % Statistics.corr(ra_ratio, width, method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(<FILL IN>\n",
    "\n",
    "ggplot(<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.regression import LassoWithSGD\n",
    "from pyspark.mllib.regression import RidgeRegressionWithSGD\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "   LabeledPoint(0.0, [0.0]),\n",
    "   LabeledPoint(10.0, [10.0]),\n",
    "   LabeledPoint(20.0, [20.0]),\n",
    "   LabeledPoint(30.0, [30.0])\n",
    "]\n",
    "lrm = LinearRegressionWithSGD.train(sc.parallelize(data), initialWeights=array([1.0]))\n",
    "print lrm\n",
    "print lrm.weights\n",
    "print lrm.intercept\n",
    "lrm.predict([40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_test = [\n",
    "   LabeledPoint(5.0, [5.0]),\n",
    "   LabeledPoint(15.0, [15.0]),\n",
    "   LabeledPoint(25.0, [25.0]),\n",
    "   LabeledPoint(35.0, [35.0])\n",
    "]\n",
    "data_test_rdd = sc.parallelize(data_test)\n",
    "valuesAndPreds = data_test_rdd.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "#\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valuesAndPreds.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP : Step Size is important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "   LabeledPoint(0.0, [0.0]),\n",
    "   LabeledPoint(9.0, [10.0]),\n",
    "   LabeledPoint(22.0, [20.0]),\n",
    "   LabeledPoint(32.0, [30.0])\n",
    "]\n",
    "lrm = LinearRegressionWithSGD.train(sc.parallelize(data), initialWeights=array([1.0])) # should be 1.09x -0.60\n",
    "        # Default step size of 1.0 will diverge\n",
    "print \"Step Size 1.0 (Default)\"\n",
    "print lrm\n",
    "print lrm.weights\n",
    "print lrm.intercept\n",
    "print \"%3.3f\" % lrm.predict([40])\n",
    "lrm = LinearRegressionWithSGD.train(sc.parallelize(data), initialWeights=array([1.0]), step=0.01) # should be 1.09x -0.60\n",
    "        # Default step size of 1.0 will diverge\n",
    "print\n",
    "print \"Step Size 0.01\"\n",
    "print lrm\n",
    "print lrm.weights\n",
    "print lrm.intercept\n",
    "print \"%3.3f\" % lrm.predict([40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "   LabeledPoint(18.9, [3910.0]),\n",
    "   LabeledPoint(17.0, [3860.0]),\n",
    "   LabeledPoint(20.0, [4200.0]),\n",
    "   LabeledPoint(16.6, [3660.0])\n",
    "]\n",
    "lrm = LinearRegressionWithSGD.train(sc.parallelize(data), step=0.00000001) # should be ~ 0.006582x -7.595170\n",
    "print lrm\n",
    "print lrm.weights\n",
    "print lrm.intercept\n",
    "lrm.predict([4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Convert the car data to labelled points\n",
    "2.  Partition to Train & Test (Weight < 4000 and >= 4000)\n",
    "3.  Train the three Linear Models\n",
    "4.  Calculate the MSE for the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "def parse_car_data(x):\n",
    "    # return labelled point\n",
    "    return LabeledPoint(x[0][0],[ x[0][1],x[0][2],x[0][3],x[0][4],x[0][5],\n",
    "                                 x[0][6],x[0][7],x[0][8],x[0][9],x[0][10],x[0][11] ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "car_rdd_lp = cars_rdd.map(<FILL IN>\n",
    "print car_rdd_lp.count()\n",
    "print car_rdd_lp.first().label\n",
    "print car_rdd_lp.first().features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "car_rdd_train = car_rdd_lp.filter(<FILL IN>\n",
    "car_rdd_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "car_rdd_test = car_rdd_lp.filter(<FILL IN>\n",
    "car_rdd_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_rdd_train.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_rdd_test.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lrm = LinearRegressionWithSGD.train(<FILL IN>\n",
    "print lrm\n",
    "print lrm.weights\n",
    "print lrm.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valuesAndPreds = car_rdd_test.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valuesAndPreds.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lrm = LassoWithSGD.train(<FILL IN>\n",
    "print lrm.weights\n",
    "print lrm.intercept\n",
    "valuesAndPreds = car_rdd_test.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valuesAndPreds.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lrm = RidgeRegressionWithSGD.train(<FILL IN>\n",
    "print lrm.weights\n",
    "print lrm.intercept\n",
    "valuesAndPreds = car_rdd_test.map(lambda p: (p.label, lrm.predict(p.features)))\n",
    "MSE = valuesAndPreds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / valuesAndPreds.count()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That is All Folks !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
